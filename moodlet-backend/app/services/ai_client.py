# app/services/ai_client.py

from openai import OpenAI
from app.core.config import settings
import json
import re
import base64
import os
import uuid

# ìŠ¤íƒ€ì¼ íƒ€ìž… & ìƒì„¸ í”„ë¡¬í”„íŠ¸ ì¡°ê°
from app.models.style_types import (
    ALL_STYLES,
    STYLE_DETAILED_INFO,
)

client = OpenAI(api_key=settings.OPENAI_API_KEY)


# --------------------------------------------------------
# 1) ê°œì¸í™”ëœ follow-up ì§ˆë¬¸ ìƒì„± (ë³€ê²½ ì—†ìŒ)
# --------------------------------------------------------
async def generate_followup_questions(user_choice_answers: dict) -> list:
    prompt = f"""
ë„ˆëŠ” ì¸í…Œë¦¬ì–´ ì·¨í–¥ ë¶„ì„ì„ ìœ„í•œ follow-up ì§ˆë¬¸ ìƒì„± ì „ë¬¸ê°€ë‹¤.

ðŸ“Œ ì‚¬ìš©ìž ì„ íƒí˜• ë‹µë³€(ë¼ë²¨ë§Œ ì¤‘ìš”):
{json.dumps(user_choice_answers, ensure_ascii=False)}

âš  value('A/B/C')ê°€ ì•„ë‹Œ label ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ ìƒì„±
â— "AìŠ¤íƒ€ì¼", "BìŠ¤íƒ€ì¼" ê°™ì€ í‘œí˜„ ê¸ˆì§€

---

ðŸŽ¯ ëª©í‘œ  
ì‚¬ìš©ìžì˜ ì·¨í–¥ì„ ë” ëª…í™•í•˜ê²Œ ì•Œ ìˆ˜ ìžˆë„ë¡  
ì„œìˆ í˜• ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•˜ë¼.

ðŸ”½ JSONë§Œ ë°˜í™˜:
[
  {{"id":"T1","text":"..."}},
  {{"id":"T2","text":"..."}},
  {{"id":"T3","text":"..."}}
]
"""

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.5,
        messages=[
            {"role": "system", "content": "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”."},
            {"role": "user", "content": prompt}
        ]
    )

    raw = resp.choices[0].message.content or ""

    try:
        data = json.loads(raw)
    except:
        match = re.search(r'\[.*\]', raw, re.DOTALL)
        if not match:
            raise Exception(f"AI ì‘ë‹µì—ì„œ JSON ë°°ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {raw}")
        data = json.loads(match.group(0))

    normalized = []
    for idx, item in enumerate(data, start=1):
        if isinstance(item, dict):
            normalized.append({
                "id": item.get("id") or f"T{idx}",
                "text": item.get("text") or ""
            })
        else:
            normalized.append({"id": f"T{idx}", "text": str(item)})

    return normalized


# --------------------------------------------------------
# 2) ìµœì¢… ìŠ¤íƒ€ì¼ ê¸°ë°˜ Best/Worst + Prompt ìƒì„± (ì˜µì…˜ B)
# --------------------------------------------------------
async def analyze_final_style(final_style: str, text_answers: dict) -> dict:
    """
    ì˜µì…˜ B:
    - finalStyleì€ ì´ë¯¸ survey_logicì—ì„œ ê³„ì‚°ëœ ìƒíƒœë¡œ ì „ë‹¬ë¨
    - AIëŠ”:
        - bestMatchStyles 2~3ê°œ
        - worstStyle 1ê°œ
        - ì˜ì–´ ì´ë¯¸ì§€ prompt ìƒì„±
    """

    if final_style not in ALL_STYLES:
        raise Exception(f"final_styleì´ ALL_STYLESì— ì†í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {final_style}")

    allowed_styles_str = ", ".join(f'"{s}"' for s in ALL_STYLES)

    prompt = f"""
ë„ˆëŠ” ì¸í…Œë¦¬ì–´ ìŠ¤íƒ€ì¼ ì „ë¬¸ê°€ë‹¤.

ðŸ“Œ ì´ë¯¸ í™•ì •ëœ ìµœì¢… ìŠ¤íƒ€ì¼:
finalStyle = "{final_style}"

ðŸ“Œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ìŠ¤íƒ€ì¼(8ê°œ):
{allowed_styles_str}

ðŸ“Œ ì‚¬ìš©ìžì˜ ì„œìˆ í˜• ë‹µë³€(textAnswers):
{text_answers}

---

í•´ì•¼ í•  ì¼:
1) finalStyleê³¼ ì¡°í™”ë¡œìš´ ìŠ¤íƒ€ì¼ 2~3ê°œë¥¼ bestMatchStylesë¡œ ì„ íƒ  
2) finalStyleê³¼ ê°€ìž¥ ëŒ€ë¹„ë˜ëŠ” ìŠ¤íƒ€ì¼ 1ê°œ(worstStyle) ì„ íƒ  
3) ìµœì¢… ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ ì˜ì–´ í”„ë¡¬í”„íŠ¸ ìƒì„±
   - roomMood, colors, materials, lighting, furniture, decor, compositionì„ í¬í•¨

ì¶œë ¥(JSONë§Œ):
{{
  "bestMatchStyles": ["...", "..."],
  "worstStyle": "...",
  "prompt": "high quality interior render ..."
}}
"""

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.25,
        messages=[
            {"role": "system", "content": "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."},
            {"role": "user", "content": prompt},
        ]
    )

    raw = resp.choices[0].message.content or ""

    try:
        data = json.loads(raw)
    except:
        match = re.search(r'\{.*\}', raw, re.DOTALL)
        if not match:
            raise Exception(f"AI JSON íŒŒì‹± ì‹¤íŒ¨: {raw}")
        data = json.loads(match.group(0))

    # ----------------------------------------------------
    # ìŠ¤íƒ€ì¼ ì½”ë“œ ìœ íš¨ì„± í•„í„°ë§
    # ----------------------------------------------------
    best = [s for s in data.get("bestMatchStyles", []) if s in ALL_STYLES]
    worst = data.get("worstStyle")
    if worst not in ALL_STYLES:
        worst = None

    # ----------------------------------------------------
    # STYLE_DETAILED_INFO ê¸°ë°˜ ìžë™ prompt ê°•í™”
    # ----------------------------------------------------
    style_info = STYLE_DETAILED_INFO.get(final_style)
    if not style_info:
        raise Exception(f"STYLE_DETAILED_INFO ëˆ„ë½: {final_style}")

    auto_prompt = (
        f"{style_info['roomMood']}, "
        f"colors: {style_info['colors']}, "
        f"materials: {style_info['materials']}, "
        f"lighting: {style_info['lighting']}, "
        f"furniture: {style_info['furniture']}, "
        f"decor: {style_info['decor']}, "
        f"composition: {style_info['composition']}, "
        f"ultra high quality interior render, 4K, photorealistic"
    )

    # AI ìƒì„± promptê°€ ìžˆë‹¤ë©´ ë³´ì¡°ì ìœ¼ë¡œ í¬í•¨í•´ë„ ë˜ê³  ë¬´ì‹œí•´ë„ ë¨
    final_prompt = auto_prompt

    return {
        "finalStyle": final_style,
        "bestMatchStyles": best,
        "worstStyle": worst,
        "prompt": final_prompt
    }


# --------------------------------------------------------
# 3) ì´ë¯¸ì§€ ìƒì„± (ê·¸ëŒ€ë¡œ ìœ ì§€)
# --------------------------------------------------------
STATIC_DIR = "static/images"

async def generate_image(prompt: str) -> str:
    img = client.images.generate(
        model="gpt-image-1-mini",
        prompt=prompt,
        size="1024x1024"
    )

    b64 = img.data[0].b64_json
    img_bytes = base64.b64decode(b64)

    file_name = f"{uuid.uuid4().hex}.png"
    file_path = f"{STATIC_DIR}/{file_name}"

    os.makedirs(STATIC_DIR, exist_ok=True)

    with open(file_path, "wb") as f:
        f.write(img_bytes)

    return f"/static/images/{file_name}"

